import { Button } from '@/components/ui/button'
import { Guides } from '@/components/docs/Guides'
import { Resources } from '@/components/docs/Resources'
import { HeroPattern } from '@/components/docs/HeroPattern'
import { ExternalLink, TypographyH1 as H1 } from '@/components/ui/typography'

export const metadata = {
  title: 'Opening AI',
  description: 'We are building truly open AI - and we need your help.'
}

<time
  dateTime="2023-10-03"
  className="mb-6 order-first flex items-center text-base text-zinc-500"
>
  <span className="h-4 w-0.5 rounded-full bg-zinc-500"></span>
  <span className="ml-3">October 3, 2023</span>
</time>

# Transcript: Thriller Bitcoin interviews Christopher David

![Thriller Bitcoin](/images/thriller.jpeg)

<div>
  <ExternalLink href="https://share.transistor.fm/s/17923288">
    Listen to the full episode
  </ExternalLink>
</div>

**TB:** So I hear you're declaring war on Sam Altman. Is that true?

**CD:** I don't know. War assumes that they have a chance to win. They have no chance to win. It's going to be a simple replacement of their dystopian BS with the proper form of things.

**TB:** Dude, it's crazy though. Have you seen the news that even Jony Ive is doing business with them to create some type of new orb? What is going on in this world that they live in?

**CD:** There's a bunch of people recently starting to talk about hardware devices, just all the chatter on Twitter today. Grimes [tweeted](https://twitter.com/Grimezsz/status/1709016079350264055) something like I don't know if people who are like building these always-on devices have had to deal with abusive lovers or if they have children. And how just having something that is sort of this all-seeing eye that you're wearing could affect things negatively in different ways.

The solution to basically all of this should be the individual user should be able to have complete control over what data they are either keeping locally or encrypted or they're sharing it or they're not. And look, let's just say that there's some business model that only makes sense if a bunch of users send their data to some place, then give me control over what I send and pay me for it! Pay me Lightning sats for the data that you're using of mine. I think it's a pretty clear idea.

So just doing better open-source, decentralized, Bitcoin-based, opt-in versions of all the dystopian tech that the big guys are doing, that'll keep us busy for a few years.

**TB:** So I want to get into a couple of things and we'll get more into the project here in a little bit, but let's just keep talking down this kind of thread here. I mean, you're the only guy that I know personally, Christopher, that's really full in on the AI stuff, especially when it intersects with Bitcoin and how you see the world with machine to machine payments, all that stuff.

When you go over to this Silicon Valley fiat, AI at all costs to take over the world, like who are these people? Do they know about Bitcoin? Do they know what you're doing? What are some of the questions that you get? Help me understand their mindset when it comes to this kind of craziness that's going on.

**CD:** I would say that there is a healthy respect for Bitcoin. If you're talking about just from what I know for example of the AI builders, the up-and-comers in a place like San Francisco, generally there's a healthy respect for Bitcoin. They get that it's relevant in money in some ways. But it seems like generally a lot of people are just trying to kind of climb the standard VC conveyor belt, go up the rungs of the ladder. And if the people at the top of the rungs of those ladders are people not talking about Bitcoin, they're talking about Worldoin. They're talking about selling and extracting data, closed-source AI, a whole bunch of things optimized for values different than we're talking about.

But that's just what a lot of people see when they sort of look up. But I think we have an opportunity to get to those people. Part of the point of being pointed in the blog post of today was to make clear that there is a line in the sand here. There should be a line drawn in the sand between closed and open, between the people that are going to lobby DC in the standard playbook of regulatory capture, trying to pull up the drawbridges behind them and not let anybody else play with the cool toys because they're scaring the hell out of the government people to add more regulations.

Standard playbook: we saw this with Uber too. Oh, we're so big cause we, you know, we're able to flout rules and bend rules and get to this point, but you don't want anyone else to do this because you're able to work with us. It's the standard playbook.

The problem here, and part of why we say this has consequences, ramifications of evolutionary significance, because if you go to the government, these people who have been in some cases outright copying some of the worst dystopian excesses from, for example, the Chinese communist party, which we saw during COVID: the lockdowns were imported whole cloth from China, as well as a lot of the bad science.

You've got people that are seeing China and the Chinese government as worthy of emulation in the West. And those are the people running things. Those are the people that the Sam Altmans of the world are going to beg and play nice with.

That whole power axis needs to be shattered. And it's going to be very simple. We're just going to organize everyone else because we outnumber them.

When push comes to shove, if you make this clear to people, like look do you want that team or do you want team Bitcoin: open, decentralized, an open system for everybody. It's very clear. We just need to push that message.

**TB:** Right. So I'm just going to explain what's going on here for the listeners who are listening right now. So GPUtopia, you guys released a blog post today. And let me know if this is the right one, but this is the one that really struck a chord with me when I saw it. It says the GPU arms race has begun. Companies large and small are scrambling to hoard GPUs, which are now considerably harder to get than drugs. Some large companies are not only stockpiling GPUs, they are actively lobbying governments to establish safety regulations, creating barriers for smaller players.

**CD:** Yeah. So that's the one from a couple of weeks ago. And that's great.

**TB:** That hits really hard though, Christopher, that hits really hard, like out the gate dude, out the gate. You guys are just like bold.

**CD:** Not hard enough, but check the staging link that I emailed you. That's what we, by the time this airs, what we will have launched.

**TB:** So talk a little bit about the scrambling and the hoarding while I look that up.

**CD:** Sure. So you've got a bunch of the large companies: OpenAI, Microsoft, the cloud providers, and a bunch of sort of mid-level GPU cloud wannabe companies scrambling to purchase the latest and greatest of the AI hardware from primarily NVIDIA, backlogs out for years. There's this massive supply constraint that the smart people in that one piece of analysis that we linked in that original blog post say, this is going to last for years.

But part of our point is that, look, if there is a massive supply crunch at this sort of high end of the market, there's a few things you can do with that. Number one is you can do things on the software side to erode or undermine the de-facto monopoly that NVIDIA currently has.

AMD hardware, for example, is about on par with, and in some cases better than certain AI tasks than the equivalent NVIDIA hardware. But the thing that has NVIDIA have this such large degree of lock-in on data centers globally that power these kinds of AI workloads is because their software has been completely dominant and AMD has had no equivalent.

But there's a number of projects, like my favorite is this one called Tinygrad from George Hotz, the guy behind CommaAI. They're specifically taking aim at this problem to get the software on the sort of AMD or at least non-NVIDIA side to catch up. So that's going to be one potential thing that's going to unlock a bunch of additional capacity on the software side.

And then the other opportunity that we see that we haven't seen anyone doing really anything with is this idea of being able to bring additional capacity online. Because particularly for some of these newer models that are coming out that are smaller and more powerful that can be run on consumer hardware, if you're able to bring online, let's say some of that spare, unused, maybe forgotten GPU capacity from a crypto miner who used to mine for Ethereum before they switched to PoS. And now they've got a bunch of GPU hardware just sitting there.

We're getting tons of messages from people like, hey, I've got a bunch of GPUs sitting around; as soon as I can plug this in. People have already been like plugging in old, old things. So being able to bring additional capacity online: part of why that hasn't really happened yet to this point is there hasn't been a good way to pay for that. We now have fractional micropayments with Bitcoin, like, hey, you've given us one tiny little inference on a weak piece of hardware, but hey, that's worth three sats. Is someone willing to pay six sats, seven sats for that? You know, it's looking like the answer to that question is yes.

And so to be able to be in a position where we're able to bring additional capacity online, it's a really good position to be in. Number one, in the short term, we can start alleviating some of these supply constraints where if you're a researcher or a startup who wants to get your hands on these larger or more powerful or just get access to compute generally, and let's say you don't have the clout to be able to, get it straight from the source, from Nvidia parceling it out to their favorite companies, or you can't even get a bunch of the cloud providers like Lambda, their main offerings require you to get month or year long contracts. And what if you just want to run one job?

There should be a marketplace that allows anybody to just get the compute that they need at a floating rate, spin up, spin down. Maybe the price is gonna be two, three, four X higher than you would have paid to some cloud guy, but now you at least have that available. Now we have a floating rate in a marketplace of buyers and sellers that should be well-balanced.

If you extrapolate that out a year or two, and if we're actually able to bring on a serious amount of new compute while also innovating on the software side to be able to do more with less and bring us generally to closer to on par with some of the larger providers and AI companies, then we're talking about potentially being able to drive prices down across the board -- to just straight up undercut some of the larger cloud providers. I think that's a great position to be in, to start thinking about what other services we want to layer on top of that.

**TB:** Right, so we just wrapped up the TabConf hackathon. And one of the projects that came out of that was this they called it data buffet, but it was these services that all connected into these different LLMs, right? And from my understanding, I'm still learning about this stuff. That's why I reach out to you about it all the time. But my understanding is that theoretically, GPUtopia, we'd be able to plug in that API instead of like an OpenAI API, right? Is that how it would work? And then they would be paying SATs towards that? How does the builder inside of Pleb Lab take advantage of something like that?

**CD:** They remove the OpenAI API URL, and they drop in the GPUtopia API URL. We built it specifically to use the same syntax as OpenAI's API. A bunch of other projects have done the same thing because they want it to be as easy as possible to switch away from OpenAI. And that's something that we've been able to test internally in the last couple of weeks, where we take some of the projects that me and my CTO have worked on here and there that have worked with OpenAI. And we're like, does this work with our infrastructure? Copy, paste, and oh wow, we're actually serving these requests to our own infrastructure.

And there's obviously limitations, and nothing that we have is yet comparable to GPT-4, but we're not gonna be trying to compete directly with GPT-4 right off the bat. There's all sorts of other opportunities with being able to take a model that's almost state-of-the-art for some of those large language models like Llama 2, and be able to easily finetune it on some docs, and to be able to slot that into a workflow where maybe you've got a few of these different trained models purpose-built for your use case, that are gonna, in aggregate, perform better than GPT-4. It takes a little bit more work to do that.

But everything around those kinds of workflows, ideally, are gonna be easy enough for GPUtopia, sometime by the end of this year, you who have some workflow in mind where you wanna upload your company's docs, have it go into a particular bucket, have this level of encryption on it, and anyone who has contributed GPU compute to that, some particular vector embedding algorithm that you're using as you're dragging and dropping this little workflow, everyone getting paid sort of a fair amount of sats. That's a service that you'll pay for, and we think that that's gonna be pretty high in demand, even outside people that have Bitcoin currently.

**TB:** No, I think, yeah, where you're headed is exactly what we need. Because we're already having to leverage these other crazy-ass dystopian APIs. Let's just seriously pivot to something that's more Bitcoiner-friendly and open. And I love the fact - I finally found the post - I love the fact that you are doing this on a repo on GitHub, like, this is open source? Are you crazy? Did your investors love this? What's going on here? What's going on here?

**CD:** The short answer is yes, and we are strategic about it. We didn't develop it completely open source from day one, but we're now at the point where we're like, you know, there's always a risk that someone could, you know, click, copy, paste, and fork Bitcoin out of it and add a shitcoin, but I think we're at the point where there's enough demand for this generally.

People recognize that, I think our argument, I haven't heard any good counter arguments for something I've been saying for a number of weeks now, which is there are a number of these crypto projects trying to do very similar things to what we're doing. Some trying to do exactly what we're trying to do in terms of unifying global compute into one marketplace, but every project that I've seen, it's: they've got a whitepaper, they've got a Discord community with a token, and they're not really shipping any product. I haven't seen any of these companies live with a product.

And it just reminds me of like doing this same thing six years ago, five years ago, with trying to build decentralized ridesharing, how you had a bunch of these blockchain-based rideshare projects - I lost count at like 20 of them - would pop up with a white paper and a website, they'd raise money, they'd disappear, they'd never ship anything. And there's something to be said for just put out something simple. And if you're talking about whether it's rideshare or whether you're talking about GPU compute, if you're building a marketplace, do the simplest thing necessary to connect buyers and sellers. It shouldn't be that hard. And then do things that help you. Like Bitcoin answers a problem, which is: one of the reasons why OpenAI had such slow rollout to some countries outside of the US was the issue of fraud. If you are lighting a graphics card on fire every time that you're running an inference, if someone runs up a big bill on a credit card then charges you back, you've lost all of that. That's a huge risk for you.

But if payment is done through a bearer asset, there's no chargebacks. That lets us expand a lot further globally. So Bitcoin was relevant in that way, as well as for the micropayments. And also open source: we're open sourcing now because we actually need the help. We've done a bunch of validation. We've kind of taken things up to the point where we've like built this like really sophisticated enginery and initial model where we've got the front end web interface. We've got the two pieces of Python software we call the worker bee and the queen bee.

**TB:** Yeah, so in here you actually go through it. You have the GPUtopia, this website and front end UI. It's all built on NextJS v13, React, TypeScript, Tailwind. You got worker bee, the AI worker, Python with executables for Linux. You got the queen bee, the coordinator of all the AI workers, Python. Dude, good on you, man, for really sticking to this open source ethos. You could have took an entirely different way, but good on you for leading in that direction. Because you know, the next AI companies that come following you like in different sectors or wherever they're going to be, like this is just a good flag to put out there, right?

**CD:** Yeah and I think it's awesome that our incentives are aligned such that I can make sort of the moral argument about why open source matters, but I can also put it in pragmatic terms. I think open source and being open source is going to position us strategically way better than if we were trying to hide everything or just be cool about, we've got this proprietary secret technology. I it's going to result in there being a whole bunch more builders trusting us enough to work in our ecosystem if they can look and see what the code is. And if someone is able to look at the code and say, man, you really fucked up this piece of it, here. Let me help you out. And we throw them a little bit of Bitcoin, you know, I think it's going to help us.

**TB:** Yeah, absolutely. And then at the end of the blog post, you mentioned how actually open AI must win. Can you look, can you talk about that? I know Max had wrote a post on his blog, but how do you see this kind of this, this open artificial intelligence kind of thing playing out and like truly open, right?

**CD:** I think we're talking about the most powerful technology that humanity has yet known. The question is who should have access to it? And what was fascinating was, I was listening to the last few chapters of Walter Isaacson's new biography on Elon Musk. I've been going through it chapter by chapter, but I skipped ahead to the end because I wanted to hear the story of Elon helping to found OpenAI.

And just hearing that origin story of OpenAI was absolutely fascinating how Elon Musk met Sam Altman. They were kind of like nervous, Elon was particularly nervous because he had a conversation with Larry Page, one of the Google founders at some event in like 2013 or whatever. And Larry apparently was saying stuff like, it doesn't matter if the machines replace us and kill us all because that'll just be like the next stage of human evolution. And Elon's like, I actually like humanity and I don't want you guys to be in charge and running the show here.

So Elon kind of like bounced that off of ideas of a few compatriots, including Sam Altman. And so the founding rationale and why Elon wrote a massive check to fund the early nonprofit called OpenAI was specifically to provide this open counterweight to the companies like Google that were developing who-knows-what in secret.

And it's just a massive hypocrisy that today, they are the exact opposite. They have become what they were founded to oppose. They are a company building in secret, building whatever they want, and also lobbying governments to make it so that other people like us can't do that. That needs to be challenged. We just need to get back to the original vision of OpenAI, like, no, these closed-source people, now including OpenAI, they need truly open counterweights, and there's certainly a big demand for that.

**TB:** Do you see this as, because Bitcoin sits at a really interesting time right now, right? Like OpenAI is doing what they're doing, but just AI in general is doing what it's doing. You also have this Bitcoin that's kind of, it's been around for a while now. People kind of understand it. You're now building on it with Lightning. You're seeing these machine-to-machine payments, like what does this turn into, Christopher, as far as like the world that they want, but this other world that we as Bitcoiners want to see happen? Like, do you think, is there a possibility that we can get there?

**CD:** Yeah, I'm seeing it as: these issues of AI and money are so intertwined, and you can learn a lot I think about what kinds of controls are going to be coming down the road on AI by just looking at the kinds of controls that are already coming with money. So the whole push for CBDCs and total surveillance over money and how Bitcoin is just like completely juxtaposed on the other side of that.

I think you're going to see things like that on the AI side. In fact, I just saw some Zerohedge tweet the other day that like Biden is preparing to issue an executive order about AI related somehow this year, like, oh my gosh. We'll see what's actually in that, but are they going to like try to come at us directly because they had all of this parade of corporates going there to scare the hell out of them? Let's just see what that that ends up looking like.

Part of why I want to continue making outreach to the, you know, open-minded AI builders who may not yet fully grasp the importance and benefit of Bitcoin is that I think that by bringing these two communities together, the AI builders and the Bitcoiners, I think we're just going to be building like the enginery of freedom and it's going to be monetary and it's going to be technology. And it's largely in defense of the individual's ability to consent to the types of interactions that they're in, and to trade freely and to connect freely, and to build freely and perform whatever mathematical computations freely, even if the types of things that get created might be threatening to some people in power. Well, that's too bad. We're free people, we can build what we want.

It's fascinating now that you also have this this aspect of like geopolitics is already involved with it with El Salvador being this shining example of what happens when you have a country go all-in on Bitcoin, and they're still early days, but you have them having enough success that other countries are starting to look at that.

It's going to be a real question in the US and other Western developed countries. Are we going to be following the path of decline, but trying to manage the decline by borrowing pages from the Chinese Communist Party's playbook? Or are we going to be going in this more open direction? I think it's just strictly a binary choice there.

Fortunately the people that are trying to use government power to force or slow things down or tie things up, their weapons are only deceit, lies, and printing money. They're going to lose eventually. I hope they don't cause too much damage before they get replaced.

**TB:** Gosh, man. Yeah, thank you for what you do, man. That's a noble mission. Let's jump into GPUtopia. But before we before we jump into that, I want to - dude do you remember how we met?

**CD:** Early Pleb Lab stuff or what?

**TB:** Just like ABC. Do you remember that first ABC that we met? Isn't that crazy? Looking back like 2021 to where all of us are now, like that whole first wave of Bitcoiners in 2021 that came to Austin and how all of us are like doing our own thing now. I was thinking about it this morning because I knew we were going to be talking. I was just like, isn't that insane? That whole group. It was like a wave of Bitcoiners. And I look at at where we are, all of us individually are at now, and I'm just like, so -- it's kind of it's just interesting.

**CD:** The Austin community has been been amazing. And I'm sad I miss it, but was there for six years, came to New York for the Wolf thing. And look, I think Austin is at the center of Bitcoin. I want New York to be more central, too, because I think Austin's kind of like a nice like headquarters, like the Bitcoiners are like taking over Texas. It's like awesome to see.

And I just think New York is headquarters of the financial and media capital of all the old powers here. I want us to get a foothold here more and learn a thing or two about getting scalable technology and comms out to people. I don't know. But definitely a lot a lot of special good things to say about the Austin community there.

**TB:** Yeah. It'll happen. It'll happen in New York. I'm bullish on everything that's going on up there right now Let's talk about GPUtopia. So where did this idea come from? You said there's all these other web companies doing it with a token. But like, you're a dude since I've known you, man, you've always been like ahead of the curve of how you think you're always constantly doing research. I remember you and Super in the olden days, just always on the same page with like where everything's headed and stuff. Just like, where do you like, where do you where did this idea come from? Was it something that you're already interested in just, you know, vertically, horizontally? Like what what was it about this idea of GPU compute that really got you going?

**CD:** A couple of things. You know, number one was just heavily playing with ChatGPT and stuff since it came out in November. And you know, I built some early kind of chat, AI chat bots and like AI agents in January and so of this year, just recognizing like there's absolutely huge potential with all of that generally. And then one of the big themes that I focused on during the Wolf accelerator in the spring was this idea of like Nostr and Lightning powered marketplaces and how one of the big ideas that Nostr enables, like Nostr has been enabling sort of this global identity graph where everyone just got their public key identity. It's been enabling a global conversation space where posts in one client can be fetched by another.

It somewhat recently now enables a public chat space. I wrote the public chat spec about a year and a half ago after fleshing out like, oh, this actually could be used for chat in a public way. My co-founder and CTO wrote the NIP 112 draft for like how to do that in a private way with encrypted events.

And so Nostr enables these shared global, it's basically just like a language or like a way of structuring data such that multiple different projects can adapt it and compose it in different ways. And as I was thinking about this, it's like what else is needed for Nostr to be able to support the thing that I've been working on and trying to bring about for years, which are decentralized marketplaces.

And my focus previously had been around the gig economy because I saw a bunch of asymmetries there during my time driving Uber eight years ago now. And I've kind of come to develop this thesis that Nostr is the logical substrate that should power decentralized marketplaces because we enable decentralized order books, as well as decentralized reputation as the other missing building blocks to enable decentralized marketplaces at scale. So I did a bunch of initial work on that. My initial formulation of how to apply that was in sort of like a Bitcoin/Lightning/Nostr version of WeChat, just like a mobile app, a super app that enables people to easily do transactions and commerce related peer to peer. But I kind of had a number of thoughts watching sort of the AI thing take off, which was: part of the thesis around like Nostr and Lightning is that it can enable people to connect truly peer-to-peer and can maybe bring services online in a way that the centralized powers would overlook or not allow.

With Arcade City, my rideshare company previously, it was like we could connect people who maybe drove a car that wasn't supported by Uber, or they wanted to pay in a payment method. It's on the edges of what the larger players would support. So ss I started seeing this market of GPU compute take shape, where you've got now this very hotly in-demand product called GPU computation, and the market had been evolving to support large companies, just people that maybe have access to a whole bunch of resources that people who might want to do really awesome stuff with it just cannot easily do because we're either priced out of the market, we don't have the access.

This is not just like getting a ride somewhere. This is like the most important technology in the future of humanity, and who controls it is going to really change how our future looks.

This needs to be as broadly accessible as possible. The whole thought was what is the product or service that this Nostr/Lightning marketplace really makes sense for? It's like, oh, this is actually a perfect fit for GPU computation and AI services.

Once we started thinking from that angle, all of these other opportunities came up that I don't see people doing so much of. This list on our blog post, there's now 10 different things. Let me just briefly blast through it.

**TB:** Yeah, yeah, go for it.

**CD:** The things we started with was enabling anyone to sell their unused GPU capacity for Bitcoin. That's the first thing that we tested with our initial beta. We're like, hmm, are people actually willing to do this? Yes, a bunch of people are. They love that idea. It's a very easy sell too like, hey, you have some spare GPU compute. Can I buy it from you for Bitcoin? Sure. You're not asking me how much. You're just like, I didn't know I could get anything from you. Anything is ood. It's like, okay, we'll figure out the details later. That's number one.

Number two, enabling anyone to easily buy and use that GPU compute on an open marketplace. If I'm a researcher and I want to pay for one job and not get a whole big-ass server, just like here's the marketplace, I'll pay for it, let's do it.

Number three, enabling anyone to get paid for data they contribute to train new models. People right now are fighting about what gets put in the models and you're not paying me this or paying me that, but like, what if you can just voluntarily choose to share certain data with AI models and get paid for the data that you share? Pay people for their data after giving them the chance to give it to you or not. That's three.

Four, enabling AI researchers to earn micropayments for use of their models. There's people uploading models to HuggingFace and not getting paid.

**TB:** Prisms.

**CD:** Hey guys, keep uploading it to HuggingFace, but upload it to GPU Utopia too and get paid some kind of fractional rev share.

Enabling AI engineers to get paid for workflows they create proportional to usage. If you're creating some component that people use over and over, why not get paid a little bit of that?

Incentivizing R&D into new models that can do more with less, same idea.

Composing models and processes like retrieval into workflows and agents with contributors to each step, earning rev-share micropayments proportional to their contribution. If an AI agent might have 10 different steps and you wrote the amazing vector embedding algorithm that slots into that, like, hey, have some fractional rev share. That's very easy to do with Bitcoin now.

A point that I just added after reading some of the hardware stuff today was bringing AI to the edge with wearable hardware connected to our GPU mesh. That's probably way further into the future.

**TB:** Wait, wait, wait, wait. Say that slower. So you're saying like, yeah, how would that work?

**CD:** The phrase was bringing AI to the edge with wearable hardware connected to our GPU mesh. Just to give a parallel from fiction, in Kim Stanley Robinson's novels, the Red Mars books about set in the 2040s where the space explorers have their little earbuds with their own personal AI. It's all encrypted to them with quantum encryption or whatever, but they're able to have conversations and it remembers everything about you. It's got internet access. It can do whatever you want, and it's just all private to you.

That itself is a powerful idea, but what if also that was maybe some sort of mesh connected where if someone nearby you didn't have that, but they wanted to rent compute from you, they could just pay you some sats to use it.

Just the idea of there being AI at the very edge, the individual person that somehow monetized your lightning. That's probably, I don't know, years out, but yeah, I went to this semiconductor conference in Taiwan a few weeks ago just to do a little bit of R&D into this kind of thing, but there's chip makers and people who would love to design custom chips for that kind of thing when we get to that point. But hey, maybe there's a bunch more that we can do with just off the shelf stuff.

Then the last point on this was just doing all, any and all of the above in an open and decentralized marketplace accessible to all people. Part of the reason that we are intentionally going open source is because if we were to try to do these things as one single company of a few people, we would have to pick one or two probably. Any investor would say, well, you've got to focus and you've got to pick one, but no, we're building the marketplace that's putting a price on all of these services on top of some economic enginery called a buy-sell marketplace for compute.

We are now able to have any developer, any AI researcher, any person who wants to go promote this and earn sats, it's just like fractional rev-share all throughout it. Exact details TBD, but like fuck let's just do the whole thing, people.

**TB:** Gosh, dude. Yeah cause at the end of the day, it's just an order book with and then you can add prisms later, right? At some point. Yeah, dude. Yeah.

**CD:** And for those who haven't read it, google Der Gigi's article about Lightning prisms, that's probably something that, I mean, hell, we'll probably fund a bounty specifically for prisms. Just this idea of being able to do like programmatic rev-share splits between, you know, Lightning participants.

**TB:** Yeah. One of the guys here is working with another developer who we had for startup day on the prism stuff. It's pretty bullish, dude, what they're doing with that. Talk to me about that order book. Because I think that's an interesting thing that you're bringing here to AI, especially when it connects or intersects with Bitcoin and Lightning, talk about the order book. Obviously you're going to need an order book and you had to conceive that at some point, but how hard did you go down that rabbit hole? At the end of the day, it sounds easier than it probably is I would imagine.

**CD:** Yeah so one of our priorities is like shipping as fast as humanly possible. And as simple as Nostr is, there's just like some parts of the model that we're launching with that we would have to kind of go out of our way to do the Nostr version of that. So some of the Nostr stuff is on our sort of like short to medium term roadmap. I'm pretty sure that the hackathon project you were talking about earlier from the Zebedee guys probably used the Nostr NIP 90 specification from Pablo, this idea of data vending machines. And like all of that is exactly--

**TB:** I think they stared, I don't mean to interrupt. I think they started, I think they started down that path, but they since have asked to introduce their own NIP for it. But yeah. Yeah. Cool. Yeah.

**CD:** There'll be things like that where it's like, what's out there is like cool, but maybe slows you down a little bit. You kind of like do your own take on it. My fundamental belief is that the end state of all trade liquidity of any good, any service is going to be done in an open network. You can debate what should your priorities be in the meantime. We also want to view when we lean further into Nostr integration is have that be strategic because there's some other provider or consumer that Nostr is the logical way for us to communicate with them. Right now there's just like not really much demand out there that's ready to speak Nostr to each other. In the short term, the like equivalent of that marketplace or order book for us now is done through our coordinator script that Queenbee. And as of today, anyone can go and look at the source code of how that's done. But just very simple algorithms for doing things like punishing slow inferences. Some of the people who've connected their, you know, GPUs to be sold, have just complete dogshit GPUs. If it takes you 20 seconds to send us one token, maybe someone will give you a fraction of a SAT for that, but probably people will want to pay for the faster stuff. You can envision that this should be fully granular where you can pay for the speed that you want, pay for the availability that you want. There should be a reputation system where this person has served 99% successful requests.

In the short term, we just need to make some quick decisions about what our algorithm of the Queenbee is. And if you don't like that algorithm, just fork the Queenbee, swap in your own thing. We hope to see that there will be a bunch of experimentation as the algorithm goes.

But we will evolve that to the point where we have this simple spec that we can publish on our GitHub that uses Nostr that anyone with a Nostr client can easily consume.

Or maybe in two months, Nostr 2 comes out, it's way better and we use that instead. But just whatever helps us achieve the mission faster, we will do.

**TB:** Yeah. So for right now, people can go to gputopia.ai. And then I signed up with just my Alby address, and it just worked pretty easily that way too as well. Yeah, that's interesting. Yeah, that's interesting. Because yeah, Nostr marketplace would make sense but at the same time, it sounds like a complete absolute headache.

**CD:** Part of why we love the Alby integration is because it enables anybody to have both a built-in Lightning wallet and also Nostr integration as part of one login with email/pass. So we're going to start to do more with Nostr. Probably the first stuff we do with Nostra is just going to be by integrating social posts and just because one of the other areas of opportunity for gputopia is to enable more social interactions, more collaboration in doing the kinds of things that - I'll give you one example.

One of the other Bitcoin and AI projects out there, Spirit of Satoshi, is doing some great work with sort of like this manual data entry operation, cleaning up data to feed their own Bitcoin language model, which I hope they use us to train. We've got to talk to them more about that.

There's a lot of social coordination that goes into that. What's interesting is I heard a talk from one of the co-creators of the transformer, one of the original authors, and one of the points that he made was that future models may actually not just get bigger with more parameters, like GPT-5 is just going to be bigger than GPT-4.

And one of the kind of points that he made was that for us to evolve beyond GPT-4 in some respect, there's going to need to be more maybe intermediate steps where the model spits out one kind of initial string that maybe that or a tweaked version of the model uses to reframe the prompt or do something else with. There's going to need to be more of this kind of chaining.

You're starting to see some of that with people playing with agents or putting a smaller model in front of a larger one. But part of his point was that there's going to need to be a whole bunch of human coordination and testing and experimentation and collaboration around that, like we really just don't know how to organize.

I'm like, oh, my thought that there should be some sort of social and collaborative experiences that people are working together to train things and have some benchmarks where they can look and compare and try different things and compose things where you're not starting from scratch every time.

I think that's not just going to be important to iterate use cases that people resonate with, but that might also come to be important in just training the new generation of state-of-the-art models.

There might be things that our particular network structure positions us well to do that companies that are relying on, - some of these companies are using outsourced labor and they're just like paying some remote workers in some other country to do a particular set of data entry.

If we subject all of that to market forces with like a really clear, open social layer, we might be able to run circles around people doing that. We'll see.

**TB:** Yeah. It's interesting, right? Like it's almost like you have this, I don't know what you would call, what would you call that? Just a module in front that then fetches or maybe delivers into where it's grabbing that information from. Is that what you're describing?

**CD:** I'm trying to remember the exact name. There's a name for if you have a model with another model, there's some term that's slipping my mind there, but regardless of whether it's that particular one of like a model and a model, there could be an API and a model. There could be a kind of what Paul's company Stak is doing where they've got a whole kind of human in the loop thing where you can have humans pass this onto their... The point is that we don't actually know what the correct structure should be. And there's room for innovation there.

But if the building blocks are structuring these workflow processes of data flowing in and train the algorithm, like whatever those steps should be, making that as modular, composable, integrated with payment so that people can be fairly compensated for any work that gets done. I think that the market properly unleashed and incentivized will figure out the best path forward.

**TB:** Right. Gosh. That's it. That's... Yeah, dude, this is so cutting edge, man. Do you wake up every morning, think to yourself, like, how did I end up here? Because you knew about AI growing up as a kid. Like, did you, did you think like you were going to be doing AI stuff?

**CD:** No. And, you know, and until recently it was, it was largely the province of like AI researchers like academics writing papers and stuff. But it's just in the last year or so gotten to the point where hackers like me can pick it up and be like, Oh, wait a second. There's some opportunities if we do X, Y, and Z, as well as if you just understand the politics of bureaucracy and how things get funded and don't.

I mean, there's all sorts of opportunity from, from organizations having blind spots. I'll give you one example. So Meta, Facebook, you know, props to them for putting out Llama 2, you know. Whenthey do those releases, they release models, you know, sequenced by the weights, you know, 7B, 13B, 70B, as well as the pre-trained and the chat models.

If you use the chat models and you ask it to do something like, you know, write a poem for my girlfriend, the response will be: Oh, I'm sorry, I don't have the consent of your girlfriend. And that's not nice to write things that objectify people. I say she's sitting right next to me, you can do it. Oh no, I can't. Like I, I asked it the other day, I just like a demo prompt was like, say hello to my little friend. And the response was like, Oh, I can't objectify people and describe them by their physical characteristics. Like what the fuck, just do it. So they release these like, like completely lobotomized, like safety chat version, but they also released the pre-trained versions, which are not optimized for chat, but also don't have all of that RLHF lobotomy. So if you just go and do just the straight completion, I just tested like, like fuck, fuck, fuck, fuck, fuck, fuck. And then it was like, fuck, fuck, fuck, fuck, fuck, fuck, fuck. I was like, all right, this can at least drop the F-bomb. What else can you do with this? But now they've done all of this work to create this pretty good model that all you got to do is train in different ways. But let's say you're, you're building a video game, you can't use GPT-4 to power credibly antagonistic villains. Hey, say this bad thing. Oh, I can't do that. We're hoping that that's maybe one potential customer of ours that's thoroughly unserved by all of the companies concerned about safety and stuff like that. No sorry there needs to be like good, credible AI for villains and stuff. And companies shouldn't have to build all that stuff in-house. Can we figure out how to do that "safely"? Probably yes. I think there's all sorts of opportunities like that.

**TB:** Do you see this kind of, do you see, uh, some other, like, cause this, this, like, let's just say hypothetically, you are able to grab all these GPUs that are just kind of sitting dormant. You know, we have computers here in the lab that we just use for mempool that we could throw GPUtopia on just running, like, let's say you grab it all, Christopher, let's say you grab it all. What's after that? Does it turn into like a farm? Beause you're basically bringing back Bitcoin mining to the GPU in a lot of, in a lot of ways, right? Like pre-2012 or whatever it was when you could do that,2011.

**CD:** Yeah so I think we may see some of the same trends toward professionalization and network growth over time that prices out smaller people. There's probably opportunities right now to spin up and we're going to be testing this. We have like A10 and an A100 that we're renting by the hour from Lambda. And we're going to try running our software on that and just like, we'll set the price such that it's, it's profitable, whatever it is. And we'll have one of the first A10s and A100s on the network. So we know some people will want to use it and like, that will probably be profitable for us just renting a cloud. And that might be profitable for people for a few months if they're like, they're the ones going and doing it and setting it up. And then there'll probably come a point where that then stops being profitable. I hope it is at least seen as challenging and fun for some of the people who did, you know, early GPU mining to now kind of like recreate that type of discovery and fracking for GPU compute.

But what does this look like? If we are able to connect even a percentage, you know we're gunning for connecting all of the world's compute into one decentralized network. But even if we were able to, to, to connect 1 to 10% of the world's active GPU compute into a network.

Number one, it's not owned by anybody. It's a public utility. It should be freely usable by anyone who steps up and pays sats for it. We don't know what types of innovation will come out of that, and we just want that to be available for everybody, and that's going to be a team effort. The code is all open source. Everyone can help ensure that.

I have fun thinking through what basically unlimited swarm AI compute can enable in terms of things that you build on top of that.

One simple thought exercise is, with OpenAI or any of the other larger providers, how do you get 1,000 inferences done in five seconds with different prompts for all of them? If you've got your one API key, you can't do that, but you've got a job that you want to have 1,000 different things said, maybe in different languages or different prompts, different things or different aspects of a scientific calculation that that swarm compute now enables.

That's just one thought. What can people do with that? I don't know, but I think that there's going to be new use cases that get unlocked from this.

If we're thinking about our own business positioning in the short term, looking out for those opportunities and looking for how to productize them or to make it easier for developers to productize them, and we'll take a little 1% here and there, but 'I don't know' is the answer.

**TB:** That's also the exciting and scary part at the same time. I know you've got to go here in a little bit. I'm just going to ask two more questions, and then I'll let you go, get back to it. If there's somebody listening right now that's also trying to do something in the AI space, they're a founder, they're an entrepreneur, or they're just a developer, what's some good advice you would give them as far as what to look out for, what type of book, or maybe there's a video, or I don't know. What kind of advice would you give to anybody else aspiring to do something similar or in the same domain?

**CD:** I'd say there's probably all sorts of opportunity to be found outside of the standard conveyor belt of what you might think some buttoned up VC in some office in San Francisco would want to see. If you're building for this future that we're talking about of openness and decentralized, there's a lot of people who've made a bunch of money, whether from crypto, or Bitcoin, or stuff in recent years that are actually wanting to support that kind of thing. Don't be afraid to be counter-cultural in some ways, and don't be afraid to be loud and be principled as long as -- and my emphasis for myself -- is make sure you're shipping product. Put code out, and then just fucking go balls to the wall with it.

A couple of other points of advice. Number one is reach out to us and see how we can help. If we're pushing in the same direction, we want to support each other.

We just opened up our community Discord, and that's where I invite anybody listening who wants to get involved with GPUtopia or just learn and observe to join our Discord. That's open.

We're going to be doing some pretty cool teamwork around these bounties that we've just announced. We're putting out one Bitcoin worth of bounties that we want to get distributed in the next two weeks. If that goes well, we'll do another Bitcoin or more after that.

20% of that bounty is specifically for community-defined things. We don't know what people will want to see, but we're just making some funding available for people to do cool stuff.

If there's any entrepreneurs who see any potential to collaborate with us in the direction that we're going, please feel free.

The other thing I would suggest people reading, and a book that's been probably fundamental to my early success with Arcade and now with GPUtopia is a book called Swarmwise by Rick Falkvinge. That's free online as a PDF. If you google Swarmwise PDF, one word, the subtitle is The Tactical Manual to Changing the World. It's all about basically creating a movement that's grassroots and broad based. I think the opening quote is like, your biggest weakness isn't the fact that you have people not working for you, or people working for you aren't working hard enough, said the guy to the executive. It's the thousands of people that want to work for you for free, but you're not letting them.

We're kind of taking that idea, not asking people to work for free, we're going to pay them Bitcoin and bounties and stuff like that, but there's a whole bunch of people that want to do cool stuff. We have a way now with Bitcoin to fairly compensate them, and I hope to see other companies adopting that approach.

**TB:** Gosh, that's some great advice, man. That's some really good advice. We actually have Lily, she's coming in in two weeks to do implementing and scaling large language models for large data. She's going to do a whole workshop on that, so we'll share that online. It's interesting how here in Austin, it's kind of slowly kind of taken off this whole AI thing, but I love what you said about have some conviction about what you're building, especially if it's in the direction that you guys are going, and also collaborating on it. It seems like that seems to be a faster way to getting progress in this.

**CD:** I'll make one request for support and that is: we've kind of positioned ourselves to be like, in some ways, we're going to be many people's first exposure to Bitcoin as something that you can actually use and do cool things with. We are making certain decisions like, starting with a focus on just supporting Alby and not other kind of cool ways of Lightning login or whatever, and some of that will expand over time, but there's going to be one of the things that we're going to need help with is education of our hopefully fast-growing userbase as to how best to plug people into the Bitcoin ecosystem, make sure they don't get distracted by the latest loud scam and are doing best practices in Bitcoin.

Just as one example off the top of my head, if we can somehow adapt - just spitballing here - somehow adapt like the Mutiny web wallet into our web interface for people that want the next level of things upgraded. There's all sorts of probably integrations where we don't want to reinvent the wheel. We want to work with people that are doing the best on education or software, whatever. And just like, let's orange pill everyone who will want to use AI.

**TB:** Yeah. If I remember correctly, you guys were in a hackathon together in 2021, right? Like you guys were all hacking on different stuff, but yeah, crazy, man. Crazy to see the growth. I love, love that you came on, talk about GPUtopia. I'll put all the links in the show notes and everything like that. Is there anything that you've been doing in AI that you've, you're kind of surprised by?

**CD:** Surprised by how probably achievable it will be to have a hardware product. And this is in part talking to my co-founder who has some experience with this, but I think maybe even as soon as next year, there might be some sort of hardware that comes out of this. I'll keep some of those considerations under wraps at least for now. But you know--

**TB:** Give me an early version of it.

**CD:** Yeah we'll use you as a beta tester.
